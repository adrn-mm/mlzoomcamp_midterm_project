{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the 'type' column\n",
    "df = pd.get_dummies(df, columns=['Type'], prefix='', prefix_sep='')\n",
    "\n",
    "# Convert the 'product ID' to numeric by extracting the numbers and categorizing the quality\n",
    "df['product_quality'] = df['Product ID'].str.extract('([LMH])')[0]\n",
    "df['product_serial'] = df['Product ID'].str.extract('(\\d+)').astype(int)\n",
    "df = df.drop('Product ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features for failure modes if needed\n",
    "conditions = [\n",
    "    # Tool Wear Failure\n",
    "    (df['Tool wear [min]'].between(200, 240)),\n",
    "    # Heat Dissipation Failure\n",
    "    ((df['Air temperature [K]'] - df['Process temperature [K]']) < 8.6) & (df['Rotational speed [rpm]'] < 1380),\n",
    "    # Power Failure\n",
    "    (df['Torque [Nm]'] * df['Rotational speed [rpm]'] / (2 * np.pi / 60)).between(3500, 9000),\n",
    "    # Overstrain Failure\n",
    "    (df['Tool wear [min]'] * df['Torque [Nm]'] > df['product_quality'].map({'L': 11000, 'M': 12000, 'H': 13000})),\n",
    "    # Random Failure\n",
    "    (np.random.rand(len(df)) < 0.001)\n",
    "]\n",
    "# the specified conditions that relate to different types of failures in the machinery\n",
    "df['failure_mode'] = np.select(conditions, [1, 2, 3, 4, 5], default=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['UDI', 'Machine failure', 'failure_mode'], axis=1)\n",
    "y = df['Machine failure']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = ['product_quality']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Cross-Validated Accuracy</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Test Accuracy  Cross-Validated Accuracy  \\\n",
       "0        RandomForest         0.9990                    0.9319   \n",
       "1    GradientBoosting         0.9985                    0.9855   \n",
       "2  LogisticRegression         0.9990                    0.9991   \n",
       "\n",
       "                               Classification Report  \n",
       "0                precision    recall  f1-score   ...  \n",
       "1                precision    recall  f1-score   ...  \n",
       "2                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate the models\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Create a full pipeline with preprocessing and the model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    results[model_name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'report': classification_report(y_test, y_pred)\n",
    "    }\n",
    "    # Cross-validation scores\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "    results[model_name]['cross_val_accuracy'] = np.mean(scores)\n",
    "\n",
    "# Print the results\n",
    "\n",
    "# Accumulate model results in a list\n",
    "data = []\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    data.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': result['accuracy'],\n",
    "        'Cross-Validated Accuracy': result['cross_val_accuracy'],\n",
    "        'Classification Report': result['report']\n",
    "    })\n",
    "\n",
    "# Convert list of results to a DataFrame\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression has the highest cross-validated accuracy, which suggests that it generalizes best to unseen data out of the three models.\n",
    "- Both Logistic Regression and Random Forest have a perfect test accuracy of 0.9990, but Random Forest has a significantly lower cross-validated accuracy.\n",
    "\n",
    "Given these results, Logistic Regression appears to be the best model in terms of generalization to new data, as indicated by its cross-validated accuracy. However, it's essential to look at the precision, recall, and f1-score for each class, especially if the classes are imbalanced or if the cost of false positives/negatives is high. If all metrics are satisfactory, Logistic Regression would be the preferred model based on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved to disk as 'LogisticRegression_model.joblib'.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'LogisticRegression' has been determined to be the best model\n",
    "best_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Create a pipeline with preprocessing and the best model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', best_model)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to disk\n",
    "joblib.dump(pipeline, '../model/LogisticRegression_model.joblib')\n",
    "\n",
    "print(\"The best model has been saved to disk as 'LogisticRegression_model.joblib'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
